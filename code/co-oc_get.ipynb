{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e4d23e7-dda0-4da7-a2e1-da656d45a20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import ast\n",
    "import os\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "\n",
    "def build_entity_cooccurrence_matrix(input_file, stopwords_file, output_file, abbreviations_file):\n",
    "    with open(stopwords_file, 'r') as f:\n",
    "        custom_stopwords = f.read().splitlines()\n",
    "    stop_words = set(stopwords.words('english') + custom_stopwords)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # Read abbreviations file\n",
    "    with open(abbreviations_file, 'r') as f:\n",
    "        abbreviations = dict(line.strip().split(',') for line in f)\n",
    "    # Read csv file\n",
    "    df = pd.read_csv(input_file)\n",
    "    # Check if named_entities column exists\n",
    "    if 'named_entities' not in df.columns:\n",
    "        raise ValueError(\"named_entities column not found in input file\")\n",
    "    # Build co-occurrence matrix for each file\n",
    "    file_cooccurrence_matrices = defaultdict(lambda: defaultdict(int))\n",
    "    total_files = len(df['filename'].unique())\n",
    "    for i, (filename, group) in enumerate(df.groupby('filename')):\n",
    "        # Process each entity in each row\n",
    "        for row in group.itertuples():\n",
    "            entities = []\n",
    "            for entity in ast.literal_eval(row.named_entities):\n",
    "                # Remove stopwords, generic entities, and special characters\n",
    "                if entity['entity_group'] != 'Generic' and entity['word'] not in stop_words:\n",
    "                    # Lemmatize entity and tokenize multiple words\n",
    "                    word = lemmatizer.lemmatize(entity['word'], pos='n')\n",
    "                    words = word_tokenize(word.lower())\n",
    "                    words = [w for w in words if w.isalnum()]\n",
    "                    entity_str = ' '.join(words)\n",
    "                    # Expand abbreviation if present\n",
    "                    if entity_str in abbreviations:\n",
    "                        entity_str = abbreviations[entity_str]\n",
    "                    # Add entity type to the entity string\n",
    "                    entity_str += f\" ({entity['entity_group']})\"\n",
    "                    entities.append(entity_str)\n",
    "            # Update co-occurrence count for each pair of entities\n",
    "            for entity1, entity2 in combinations(entities, 2):\n",
    "                if entity1 == entity2:\n",
    "                    continue\n",
    "                sorted_entities = tuple(sorted([entity1, entity2]))\n",
    "                file_cooccurrence_matrices[filename][sorted_entities] += 1\n",
    "        # Print progress every 10% completion\n",
    "        percent_complete = (i + 1) / total_files * 100\n",
    "        if percent_complete % 10 == 0:\n",
    "            print(f\"Processing {filename} ({percent_complete:.0f}% complete)...\")\n",
    "    # Write entity co-occurrence count to csv file\n",
    "    with open(output_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['filename', 'entity1', 'entity2', 'cooccurrence', 'entity1_type', 'entity2_type'])\n",
    "        for filename, entity_cooccurrence_matrix in file_cooccurrence_matrices.items():\n",
    "            for entities, cooccurrence in entity_cooccurrence_matrix.items():\n",
    "                entity1, entity2 = entities\n",
    "                entity1_type = entity1.split(' ')[-1][1:-1]\n",
    "                entity2_type = entity2.split(' ')[-1][1:-1]\n",
    "                entity1 = ' '.join(entity1.split(' ')[:-1])\n",
    "                entity2 = ' '.join(entity2.split(' ')[:-1])\n",
    "                writer.writerow([filename, entity1, entity2, cooccurrence, entity1_type, entity2_type])\n",
    "    # Read csv file and output top 10 co-occurring entities per file\n",
    "    df = pd.read_csv(output_file)\n",
    "    df_sorted = df.sort_values(['filename', 'cooccurrence'], ascending=[True, False])\n",
    "    print(df_sorted.groupby('filename').head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3376fc88-d137-42dc-acd6-ddebf79b6725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ac4d4cf-b162-4bc9-91fb-9e1210e43cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/featurize/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/featurize/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/featurize/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21525995-6176-4d59-9541-93c4054988b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Uuf2q9TfXGA.xml (50% complete)...\n",
      "Processing zzqBoIFOQ1.xml (100% complete)...\n",
      "               filename                 entity1            entity2  \\\n",
      "782      -0tPmzgXS5.xml            ghost motion                 gm   \n",
      "947      -0tPmzgXS5.xml                      gm        randaugment   \n",
      "865      -0tPmzgXS5.xml                      gm  video recognition   \n",
      "41       -0tPmzgXS5.xml             overfitting              video   \n",
      "832      -0tPmzgXS5.xml  generalization ability                 gm   \n",
      "...                 ...                     ...                ...   \n",
      "6749757  zzqBoIFOQ1.xml                csc mbpo              spice   \n",
      "6749535  zzqBoIFOQ1.xml       environment model              spice   \n",
      "6749815  zzqBoIFOQ1.xml       environment model             policy   \n",
      "6750258  zzqBoIFOQ1.xml          safety horizon  safety violations   \n",
      "6748876  zzqBoIFOQ1.xml         safety analysis              spice   \n",
      "\n",
      "         cooccurrence         entity1_type         entity2_type  \n",
      "782                12               Method               Method  \n",
      "947                 7               Method               Method  \n",
      "865                 6               Method                 Task  \n",
      "41                  5  OtherScientificTerm             Material  \n",
      "832                 5               Metric               Method  \n",
      "...               ...                  ...                  ...  \n",
      "6749757             6               Method               Method  \n",
      "6749535             5  OtherScientificTerm               Method  \n",
      "6749815             5  OtherScientificTerm  OtherScientificTerm  \n",
      "6750258             5  OtherScientificTerm  OtherScientificTerm  \n",
      "6748876             4                 Task               Method  \n",
      "\n",
      "[38120 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "input_file = 'iclr_output.csv'\n",
    "stopwords_file = 'stopwords.txt'\n",
    "output_file = 'co_ent_iclr.csv'\n",
    "abbreviations_file = 'abbreviations_file.txt'\n",
    "build_entity_cooccurrence_matrix(input_file, stopwords_file, output_file, abbreviations_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21f34688-59a8-4c83-a7b4-1deb04374fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CSV file has 22537 rows after filtering.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('co_ent_arxiv.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)  # 跳过第一行表头\n",
    "    filtered_rows = [row for row in reader if int(row[2]) >= 10]\n",
    "    row_count = len(filtered_rows)\n",
    "\n",
    "    print(f'The CSV file has {row_count} rows after filtering.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8477f663-7365-4dbc-8696-f158dff3414e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                filename               entity1                      entity2  \\\n",
      "1944352  HcUf-QwZeFh.xml               iboetvq                        sfbdi   \n",
      "1077709  8aHzds2uUyB.xml                   col                       header   \n",
      "5942909  rnFOPhTMB0Y.xml                 adamw  stochastic gradient descent   \n",
      "1944351  HcUf-QwZeFh.xml                 sfbdi                        upvdi   \n",
      "3092561  SNONkz5zEUF.xml    federated learning                           sl   \n",
      "3194165   TMYzh1hsHd.xml                   iql                        ma2ql   \n",
      "3458964  VWm4o4l3V9e.xml                  bsfp                         msfp   \n",
      "2741805  P8YIphWNEGO.xml  graph neural network                      peermlp   \n",
      "5943194  rnFOPhTMB0Y.xml          freeze embed  stochastic gradient descent   \n",
      "1944355  HcUf-QwZeFh.xml               iboetvq                        upvdi   \n",
      "3555684  WZH7099tgfM.xml                  jump                   turn right   \n",
      "4105745   azCKuYyS74.xml                    cl                          mim   \n",
      "1598530  DvMDIEFtyjV.xml                 clutr                       paired   \n",
      "5944116  rnFOPhTMB0Y.xml                 adamw                 freeze embed   \n",
      "5425000  moIlFZfj_1b.xml                   dec                        θ dyn   \n",
      "742252    5cAI0qXxyv.xml                     n                           wl   \n",
      "3555163  WZH7099tgfM.xml                  jump                    turn left   \n",
      "4698026  gPWtHmCaBiY.xml                   fpf                        k fpf   \n",
      "742080    5cAI0qXxyv.xml                     n                           wl   \n",
      "6064794   svCcui6Drl.xml             local sgd  stochastic gradient descent   \n",
      "\n",
      "         cooccurrence         entity1_type         entity2_type  \n",
      "1944352           375  OtherScientificTerm  OtherScientificTerm  \n",
      "1077709           272  OtherScientificTerm  OtherScientificTerm  \n",
      "5942909           270               Method               Method  \n",
      "1944351           200  OtherScientificTerm  OtherScientificTerm  \n",
      "3092561           144               Method               Method  \n",
      "3194165           136               Method               Method  \n",
      "3458964           130               Method               Method  \n",
      "2741805           129               Method               Method  \n",
      "5943194           124               Method               Method  \n",
      "1944355           120  OtherScientificTerm  OtherScientificTerm  \n",
      "3555684           115  OtherScientificTerm  OtherScientificTerm  \n",
      "4105745           115               Method               Method  \n",
      "1598530           109               Method               Method  \n",
      "5944116           107               Method               Method  \n",
      "5425000           105  OtherScientificTerm  OtherScientificTerm  \n",
      "742252            104               Method               Method  \n",
      "3555163            98  OtherScientificTerm  OtherScientificTerm  \n",
      "4698026            94               Method               Method  \n",
      "742080             93  OtherScientificTerm  OtherScientificTerm  \n",
      "6064794            89               Method               Method  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read entity co-occurrence count from csv file\n",
    "df = pd.read_csv(output_file)\n",
    "\n",
    "# Sort by cooccurrence in descending order and output top 20 rows\n",
    "df_sorted = df.sort_values('cooccurrence', ascending=False)\n",
    "print(df_sorted.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b38aed6-35e4-4a4f-aa7d-06fbadca0774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read entity co-occurrence count from csv file\n",
    "df = pd.read_csv('co_ent_arxiv.csv')\n",
    "\n",
    "# Extract entity types from entity1_type and entity2_type columns\n",
    "entity_types = set(df['entity1_group']).union(set(df['entity2_group']))\n",
    "\n",
    "# Create a dictionary to store the count of each entity type\n",
    "entity_type_counts = {}\n",
    "\n",
    "# Count number of entities for each type\n",
    "for entity_type in entity_types:\n",
    "    entity_type_counts[entity_type] = df[(df['entity1_group'] == entity_type) | (df['entity2_group'] == entity_type)]['entity1'].nunique() + df[(df['entity1_group'] == entity_type) | (df['entity2_group'] == entity_type)]['entity2'].nunique()\n",
    "\n",
    "# Print entity type counts\n",
    "for entity_type, count in entity_type_counts.items():\n",
    "    print(f\"{entity_type}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c8509f-51eb-436d-bc26-91dcca7076b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
